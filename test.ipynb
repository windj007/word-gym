{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from pandas import DataFrame\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "        \n",
    "    def batches(self, dictionary=False, batch_size=20):\n",
    "        raw_text = self.corpus\n",
    "        if dictionary:\n",
    "            for i in self._split_sentences(raw_text):\n",
    "                yield i\n",
    "        else:\n",
    "            while raw_text:\n",
    "                yield raw_text[:batch_size]\n",
    "                raw_text = raw_text[batch_size:] \n",
    "            \n",
    "    def _split_sentences(self, text, batch_size=20):\n",
    "        batches = []\n",
    "        for sentence in sent_tokenize(text):\n",
    "            for i in self._find_neighbors(sentence):\n",
    "                batches.append(i)\n",
    "                if len(batches) > batch_size:\n",
    "                    yield(batches)\n",
    "                    batches = []\n",
    "        yield(batches)\n",
    "\n",
    "\n",
    "    def _find_neighbors(self, text_batch, window=3):\n",
    "            words = word_tokenize(text_batch)\n",
    "            for word_id, word in enumerate(words):\n",
    "                lower_bound = word_id-window\n",
    "                if word_id-window < 0:\n",
    "                    lower_bound = 0\n",
    "                d = {}\n",
    "                d[word] = words[lower_bound:word_id] + words[word_id+1:word_id+window]\n",
    "                yield(d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings():\n",
    "    def __init__(self, embeddings='Word2Vec'):\n",
    "        self.model = self.init_model(embeddings)\n",
    "        \n",
    "    def init_model(self, embeddings):\n",
    "        if embeddings == 'Word2Vec':\n",
    "            return Word2Vec()\n",
    "        \n",
    "    def fit_corpus(self, text):\n",
    "        corpus = Corpus(text)\n",
    "        self.batches = [batch.split(' ') for batch in list(corpus.batches(dictionary=False))]\n",
    "        \n",
    "    def _build_vocab(self, batches):\n",
    "        self.model.build_vocab(batches)\n",
    "\n",
    "    def _train_model(self, batches, epochs=3):\n",
    "        self.model.train(batches, total_examples=len(batches), epochs=epochs)\n",
    "        \n",
    "    def train(self):\n",
    "        self._build_vocab(self.batches)\n",
    "        self._train_model(self.batches)\n",
    "        \n",
    "    def vector(self, word):\n",
    "        return self.model[word]\n",
    "        \n",
    "    def online_training(self):\n",
    "        for batch in batches:\n",
    "            model.build_vocab(batch, update=True)\n",
    "            model.train(batch, total_examples=10, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "    def __init__(self, test='word_similarity', datasets=['wordsim353-rel'], metric='spearman'):\n",
    "        self.datasets_dir = 'datasets'\n",
    "        \n",
    "        self.test = test\n",
    "        self.datasets = [DataFrame.from_csv(path.join(self.datasets_dir, test, '{}.csv'.format(dataset))).dropna() for dataset in datasets]\n",
    "        self.metric = metric\n",
    "        \n",
    "    def evaluate(self, model):\n",
    "        similarities = {'model':[], 'human':[]}\n",
    "        for dataset in self.datasets:\n",
    "            for index, row in dataset.iterrows():\n",
    "                try:\n",
    "                    similarities['model'].append(1 - cosine(model.vector(row['word1']), model.vector(row['word2'])))\n",
    "                    similarities['human'].append(row['similarity'])\n",
    "                except KeyError:\n",
    "                    pass\n",
    "        if self.metric == 'spearman':\n",
    "            return spearmanr(similarities['model'], similarities['human'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline():\n",
    "    def __init__(self, text, model='Word2Vec'):\n",
    "        self.model = Embeddings(model)\n",
    "        self.model.fit_corpus(text)\n",
    "        self.model.train()\n",
    "    \n",
    "    def evaluate(self, test='word-similarity', datasets=['wordsim353-rel']):\n",
    "        evaluator = Evaluator(test='word-similarity', datasets=['wordsim353-rel'], metric='spearman')\n",
    "        return evaluator.evaluate(self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path.join('data', 'pidgeons.txt'), 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=nan, pvalue=nan)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Pipeline(text=text, model='Word2Vec')\n",
    "p.evaluate(test='word_similarity', datasets=['wordsim353-rel'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
